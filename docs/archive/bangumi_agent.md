# BangumiResolverAgent å®æ–½è®¡åˆ’

> åŸºäºè®¾è®¡æ–‡æ¡£ `bangumi-resolver-agent-design.md` çš„è¯¦ç»†å®æ–½æŒ‡å—
>
> éµå¾ªåŸåˆ™: TDD + CLEAN CODE + SOLID + KISS

**ç‰ˆæœ¬**: 1.0
**åˆ›å»ºæ—¥æœŸ**: 2025-11-28
**çŠ¶æ€**: å¾…å®æ–½

---

## ç›®å½•

- [æ€»ä½“æ¶æ„](#æ€»ä½“æ¶æ„)
- [Stage 1: BangumiClient](#stage-1-bangumiClient-api-å®¢æˆ·ç«¯å±‚)
- [Stage 2: BangumiResolverAgent](#stage-2-bangumiresolveragent-æ ¸å¿ƒé€»è¾‘å±‚)
- [Stage 3: SearchAgent ä¿®æ”¹](#stage-3-searchagent-ä¿®æ”¹)
- [Stage 4: OrchestratorAgent é›†æˆ](#stage-4-orchestratoragent-é›†æˆ)
- [Stage 5: å®Œæ•´æµ‹è¯•å¥—ä»¶](#stage-5-å®Œæ•´æµ‹è¯•å¥—ä»¶)
- [éªŒæ”¶æ ‡å‡†](#éªŒæ”¶æ ‡å‡†)

---

## æ€»ä½“æ¶æ„

### æ•°æ®æµå‘å›¾

```
ç”¨æˆ·æŸ¥è¯¢: "æˆ‘åœ¨æ–°å®¿ç«™ï¼Œæƒ³å»ã€Šä½ çš„åå­—ã€‹çš„åœ£åœ°"
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         BangumiResolverAgent (æ–°å¢)                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Step 1: LLM æå–ç•ªå‰§åç§°                             â”‚   â”‚
â”‚  â”‚  Input:  "æˆ‘åœ¨æ–°å®¿ç«™ï¼Œæƒ³å»ã€Šä½ çš„åå­—ã€‹çš„åœ£åœ°"          â”‚   â”‚
â”‚  â”‚  Output: "ä½ çš„åå­—"                                  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                        â†“                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Step 2: BangumiClient è°ƒç”¨ Bangumi API æœç´¢          â”‚   â”‚
â”‚  â”‚  Request: GET /search/subject/ä½ çš„åå­—?type=2        â”‚   â”‚
â”‚  â”‚  Response: [{id: 160209, name_cn: "ä½ çš„åå­—ã€‚"}, ...]â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                        â†“                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Step 3: LLM é€‰æ‹©æœ€ä½³åŒ¹é…                             â”‚   â”‚
â”‚  â”‚  Input:  æœç´¢ç»“æœåˆ—è¡¨ + ç”¨æˆ·åŸå§‹æŸ¥è¯¢                  â”‚   â”‚
â”‚  â”‚  Output: {id: 160209, confidence: 0.95}              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
            Bangumi ID: 160209
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              SearchAgent (ä¿®æ”¹å)                            â”‚
â”‚  - æ¥æ”¶ bangumi_id å’Œ user_query                            â”‚
â”‚  - è°ƒç”¨ Anitabi: /bangumi/160209/points/detail              â”‚
â”‚  - è·å–è¯¥ç•ªå‰§çš„æ‰€æœ‰åœ£åœ°åˆ—è¡¨                                  â”‚
â”‚  - æå–ç”¨æˆ·ä½ç½®ï¼Œè®¡ç®—è·ç¦»å¹¶æ’åº                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ç»„ä»¶èŒè´£

| ç»„ä»¶ | èŒè´£ | è¾“å…¥ | è¾“å‡º |
|------|------|------|------|
| **BangumiClient** | å°è£… Bangumi API è°ƒç”¨ | æœç´¢å…³é”®è¯ | ç•ªå‰§æœç´¢ç»“æœåˆ—è¡¨ |
| **BangumiResolverAgent** | ç•ªå‰§å â†’ ID è§£æ | ç”¨æˆ·æŸ¥è¯¢æ–‡æœ¬ | Bangumi ID + å…ƒæ•°æ® |
| **SearchAgent** (ä¿®æ”¹) | ID â†’ åœ£åœ°åˆ—è¡¨ | Bangumi ID + ç”¨æˆ·ä½ç½® | åœ£åœ°åˆ—è¡¨ï¼ˆå¸¦è·ç¦»ï¼‰ |
| **OrchestratorAgent** (ä¿®æ”¹) | å·¥ä½œæµåè°ƒ | ç”¨æˆ·å®Œæ•´æŸ¥è¯¢ | å®Œæ•´æ—…è¡Œè®¡åˆ’ |

---

## Stage 1: BangumiClient (API å®¢æˆ·ç«¯å±‚)

### ç›®æ ‡

å°è£… Bangumi API è°ƒç”¨é€»è¾‘ï¼Œæä¾›ç±»å‹å®‰å…¨çš„æœç´¢å’Œè¯¦æƒ…æŸ¥è¯¢åŠŸèƒ½ã€‚

### è¾“å…¥è¾“å‡ºè§„èŒƒ

#### è¾“å…¥

```python
# æœç´¢ç•ªå‰§
keyword: str = "ä½ çš„åå­—"
subject_type: int = 2  # 2=åŠ¨ç”», 1=ä¹¦ç±, 3=éŸ³ä¹, 4=æ¸¸æˆ
max_results: int = 10  # 1-20
```

#### è¾“å‡º

```python
# è¿”å›å€¼: List[Dict]
[
    {
        "id": 160209,
        "name": "å›ã®åã¯ã€‚",
        "name_cn": "ä½ çš„åå­—ã€‚",
        "type": 2,
        "images": {
            "large": "http://lain.bgm.tv/pic/cover/l/20/15/160209_2UzU8.jpg",
            "medium": "...",
            "small": "..."
        },
        "url": "http://bgm.tv/subject/160209",
        "rating": {
            "score": 8.1,
            "total": 31121
        }
    },
    ...
]
```

### è¦ä¿®æ”¹çš„æ–‡ä»¶

1. âœ¨ **æ–°å»º**: `clients/bangumi.py`
2. ğŸ“ **ä¿®æ”¹**: `clients/__init__.py`
3. âœ… **æ–°å»º**: `tests/unit/test_bangumi_client.py`

### TDD å®æ–½æ­¥éª¤

#### æ­¥éª¤ 1.1: å†™æµ‹è¯• (RED é˜¶æ®µ)

**æ–‡ä»¶**: `tests/unit/test_bangumi_client.py`

```python
"""
Unit tests for BangumiClient following TDD principles.
Tests written BEFORE implementation (RED phase).
"""

import pytest
from unittest.mock import Mock, AsyncMock, patch
import aiohttp

from clients.bangumi import BangumiClient
from domain.entities import APIError


@pytest.fixture
def bangumi_client():
    """Create a BangumiClient instance."""
    return BangumiClient()


class TestBangumiClient:
    """Test suite for BangumiClient."""

    @pytest.mark.asyncio
    async def test_search_subject_returns_results(self, bangumi_client):
        """Test search_subject returns valid results."""
        # Arrange
        keyword = "ä½ çš„åå­—"

        # Act
        results = await bangumi_client.search_subject(keyword)

        # Assert
        assert isinstance(results, list)
        assert len(results) > 0

        # Verify result structure
        first_result = results[0]
        assert "id" in first_result
        assert "name" in first_result
        assert isinstance(first_result["id"], int)

    @pytest.mark.asyncio
    async def test_search_subject_url_encoding(self, bangumi_client):
        """Test that keywords with special chars are URL encoded."""
        # Arrange
        keyword = "å¹å“ï¼ä¸Šä½éŸ³å·"  # Contains special chars

        # Act
        results = await bangumi_client.search_subject(keyword)

        # Assert
        assert isinstance(results, list)
        # Should not raise encoding errors

    @pytest.mark.asyncio
    async def test_search_subject_with_type_filter(self, bangumi_client):
        """Test search with subject type filter."""
        # Arrange
        keyword = "ä½ çš„åå­—"

        # Act
        results = await bangumi_client.search_subject(
            keyword,
            subject_type=2,  # Anime only
            max_results=5
        )

        # Assert
        assert len(results) <= 5
        # All results should be type 2 (anime)
        for result in results:
            assert result.get("type") == 2

    @pytest.mark.asyncio
    async def test_search_subject_empty_results(self, bangumi_client):
        """Test search with no results returns empty list."""
        # Arrange
        keyword = "xyzabc123notexist999"

        # Act
        results = await bangumi_client.search_subject(keyword)

        # Assert
        assert isinstance(results, list)
        assert len(results) == 0

    @pytest.mark.asyncio
    async def test_search_subject_uses_cache(self, bangumi_client):
        """Test that repeated searches use cache."""
        # Arrange
        keyword = "ä½ çš„åå­—"

        # Act - First call
        results1 = await bangumi_client.search_subject(keyword)

        # Act - Second call (should hit cache)
        results2 = await bangumi_client.search_subject(keyword)

        # Assert
        assert results1 == results2
        # TODO: Verify cache hit via logs or metrics

    @pytest.mark.asyncio
    async def test_search_subject_api_error_handling(self):
        """Test API error handling."""
        # Arrange
        client = BangumiClient()

        # Mock the get method to raise an error
        with patch.object(client, 'get', side_effect=APIError("API Error")):
            # Act & Assert
            with pytest.raises(APIError):
                await client.search_subject("test")

    @pytest.mark.asyncio
    async def test_search_subject_includes_user_agent(self, bangumi_client):
        """Test that requests include proper User-Agent header."""
        # This is important for Bangumi API best practices
        # Will be verified in implementation via headers
        keyword = "test"

        # For now, just ensure it doesn't raise
        results = await bangumi_client.search_subject(keyword)
        assert isinstance(results, list)

    @pytest.mark.asyncio
    async def test_get_subject_by_id(self, bangumi_client):
        """Test fetching subject details by ID."""
        # Arrange
        subject_id = 160209  # ä½ çš„åå­—

        # Act
        result = await bangumi_client.get_subject(subject_id)

        # Assert
        assert result["id"] == subject_id
        assert "name" in result
        assert "name_cn" in result
        assert "rating" in result

    @pytest.mark.asyncio
    async def test_client_rate_limiting(self, bangumi_client):
        """Test that client respects rate limits."""
        # Make multiple rapid requests
        keyword = "test"

        # Act - Make 5 rapid requests
        results = []
        for _ in range(5):
            result = await bangumi_client.search_subject(keyword)
            results.append(result)

        # Assert - Should complete without rate limit errors
        assert len(results) == 5
```

**è¿è¡Œæµ‹è¯•** (åº”è¯¥å…¨éƒ¨å¤±è´¥):
```bash
pytest tests/unit/test_bangumi_client.py -v
```

#### æ­¥éª¤ 1.2: å®ç°ä»£ç  (GREEN é˜¶æ®µ)

**æ–‡ä»¶**: `clients/bangumi.py`

```python
"""
Bangumi API client for anime/manga metadata.

Official API: https://bangumi.github.io/api/
Provides methods to:
- Search for anime/manga by keyword
- Retrieve subject details by ID
"""

from typing import List, Dict, Optional
import urllib.parse

from clients.base import BaseHTTPClient
from domain.entities import APIError
from utils.logger import get_logger
from config.settings import get_settings

logger = get_logger(__name__)
settings = get_settings()


class BangumiClient(BaseHTTPClient):
    """
    Client for Bangumi API (ç•ªçµ„è¨ˆç”» API).

    Provides access to anime/manga metadata including:
    - Subject search by keyword
    - Subject details by ID
    - Ratings and reviews

    Note: Search endpoints do NOT require authentication.
    """

    # API Constants
    BANGUMI_API_BASE = "https://api.bgm.tv"
    USER_AGENT = "Seichijunrei/1.0 (https://github.com/yourusername/seichijunrei)"

    # Subject Types
    TYPE_BOOK = 1
    TYPE_ANIME = 2
    TYPE_MUSIC = 3
    TYPE_GAME = 4
    TYPE_REAL = 6

    def __init__(
        self,
        base_url: Optional[str] = None,
        use_cache: bool = True,
        rate_limit_calls: int = 30,
        rate_limit_period: float = 60.0
    ):
        """
        Initialize Bangumi API client.

        Args:
            base_url: Override base URL (default: https://api.bgm.tv)
            use_cache: Whether to cache GET responses (default: True)
            rate_limit_calls: Number of calls allowed per period
            rate_limit_period: Rate limit period in seconds
        """
        super().__init__(
            base_url=base_url or self.BANGUMI_API_BASE,
            api_key=None,  # No API key needed for search
            timeout=10,
            max_retries=3,
            rate_limit_calls=rate_limit_calls,
            rate_limit_period=rate_limit_period,
            use_cache=use_cache,
            cache_ttl_seconds=86400  # Cache for 24 hours
        )

        logger.info(
            "Bangumi client initialized",
            base_url=self.base_url,
            cache_enabled=use_cache,
            rate_limit=f"{rate_limit_calls}/{rate_limit_period}s"
        )

    async def search_subject(
        self,
        keyword: str,
        subject_type: int = TYPE_ANIME,
        max_results: int = 10
    ) -> List[Dict]:
        """
        Search for subjects by keyword.

        Args:
            keyword: Search keyword (anime/manga name)
            subject_type: Type filter (1=book, 2=anime, 3=music, 4=game, 6=real)
            max_results: Maximum results to return (1-20)

        Returns:
            List of subject dictionaries with id, name, name_cn, type, images, etc.

        Raises:
            APIError: On API communication failure
            ValueError: On invalid parameters
        """
        # Validate parameters
        if not keyword or not keyword.strip():
            raise ValueError("Keyword cannot be empty")

        if not 1 <= max_results <= 20:
            raise ValueError("max_results must be between 1 and 20")

        try:
            logger.info(
                "Searching bangumi subjects",
                keyword=keyword,
                subject_type=subject_type,
                max_results=max_results
            )

            # URL encode the keyword
            encoded_keyword = urllib.parse.quote(keyword)

            # Make API request
            response = await self.get(
                f"/search/subject/{encoded_keyword}",
                params={
                    "type": subject_type,
                    "max_results": max_results
                },
                headers={
                    "User-Agent": self.USER_AGENT
                }
            )

            # Extract results
            results = response.get("list", [])

            logger.info(
                "Bangumi search completed",
                keyword=keyword,
                results_count=len(results)
            )

            return results

        except APIError:
            # Re-raise API errors
            raise

        except Exception as e:
            logger.error(
                "Bangumi search failed",
                keyword=keyword,
                error=str(e),
                exc_info=True
            )
            raise APIError(f"Bangumi search failed: {str(e)}")

    async def get_subject(self, subject_id: int) -> Dict:
        """
        Get detailed information about a subject by ID.

        Args:
            subject_id: Bangumi subject ID

        Returns:
            Subject details dictionary

        Raises:
            APIError: On API communication failure
            ValueError: On invalid subject_id
        """
        if subject_id <= 0:
            raise ValueError("subject_id must be positive")

        try:
            logger.info(
                "Fetching bangumi subject details",
                subject_id=subject_id
            )

            response = await self.get(
                f"/subject/{subject_id}",
                headers={
                    "User-Agent": self.USER_AGENT
                }
            )

            logger.info(
                "Bangumi subject fetched",
                subject_id=subject_id,
                name=response.get("name")
            )

            return response

        except APIError:
            raise

        except Exception as e:
            logger.error(
                "Failed to fetch bangumi subject",
                subject_id=subject_id,
                error=str(e),
                exc_info=True
            )
            raise APIError(f"Failed to fetch subject {subject_id}: {str(e)}")
```

**æ›´æ–°**: `clients/__init__.py`

```python
"""
Client modules for external API integrations.
"""

from clients.anitabi import AnitabiClient
from clients.bangumi import BangumiClient  # æ–°å¢
from clients.google_maps import GoogleMapsClient
from clients.weather import WeatherClient

__all__ = [
    "AnitabiClient",
    "BangumiClient",  # æ–°å¢
    "GoogleMapsClient",
    "WeatherClient",
]
```

**è¿è¡Œæµ‹è¯•** (åº”è¯¥é€šè¿‡):
```bash
pytest tests/unit/test_bangumi_client.py -v
```

#### æ­¥éª¤ 1.3: é‡æ„ (REFACTOR é˜¶æ®µ)

**ä¼˜åŒ–ç‚¹**:

1. **æå–å¸¸é‡**
```python
# clients/bangumi.py

# Subject Types (already done above)
TYPE_BOOK = 1
TYPE_ANIME = 2
...

# API Limits
MAX_SEARCH_RESULTS = 20
DEFAULT_SEARCH_RESULTS = 10
CACHE_TTL_SECONDS = 86400  # 24 hours
```

2. **æ”¹è¿›é”™è¯¯æ¶ˆæ¯**
```python
# More specific error messages
if not keyword.strip():
    raise ValueError(
        "Search keyword cannot be empty. "
        "Please provide a valid anime/manga name."
    )
```

3. **æ·»åŠ ç±»å‹æç¤º**
```python
from typing import List, Dict, Optional, Literal

SubjectType = Literal[1, 2, 3, 4, 6]

async def search_subject(
    self,
    keyword: str,
    subject_type: SubjectType = TYPE_ANIME,
    max_results: int = DEFAULT_SEARCH_RESULTS
) -> List[Dict[str, Any]]:
    ...
```

4. **æ·»åŠ æ–‡æ¡£å­—ç¬¦ä¸²ç¤ºä¾‹**
```python
async def search_subject(...):
    """
    Search for subjects by keyword.

    Example:
        >>> client = BangumiClient()
        >>> results = await client.search_subject("ä½ çš„åå­—")
        >>> print(results[0]["name_cn"])
        'ä½ çš„åå­—ã€‚'

    ...
    """
```

**å†æ¬¡è¿è¡Œæµ‹è¯•** (ç¡®ä¿é‡æ„åä»ç„¶é€šè¿‡):
```bash
pytest tests/unit/test_bangumi_client.py -v
```

### éªŒæ”¶æ ‡å‡† (Stage 1)

- [x] æµ‹è¯•è¦†ç›–ç‡ > 90%
- [x] æ‰€æœ‰æµ‹è¯•é€šè¿‡
- [x] æ”¯æŒ URL ç¼–ç 
- [x] æ”¯æŒç¼“å­˜æœºåˆ¶
- [x] æ”¯æŒé™æµ
- [x] é”™è¯¯å¤„ç†å®Œå–„
- [x] ä»£ç é€šè¿‡ ruff/black æ£€æŸ¥

---

## Stage 2: BangumiResolverAgent (æ ¸å¿ƒé€»è¾‘å±‚)

### ç›®æ ‡

å®ç°æ™ºèƒ½è§£æAgentï¼Œå°†ç”¨æˆ·è‡ªç„¶è¯­è¨€æŸ¥è¯¢è½¬æ¢ä¸ºç²¾ç¡®çš„ Bangumi IDã€‚

### è¾“å…¥è¾“å‡ºè§„èŒƒ

#### è¾“å…¥

```python
AgentInput(
    session_id="session-20251128-001",
    data={
        "user_query": "æˆ‘åœ¨æ–°å®¿ç«™ï¼Œæƒ³å»ã€Šä½ çš„åå­—ã€‹çš„åœ£åœ°"
    }
)
```

#### è¾“å‡º

```python
AgentOutput(
    success=True,
    data={
        "id": 160209,
        "name": "å›ã®åã¯ã€‚",
        "name_cn": "ä½ çš„åå­—ã€‚",
        "confidence": 0.95,
        "reasoning": "åç§°å®Œå…¨åŒ¹é…ï¼Œä¸”ä¸ºè¯¥æŸ¥è¯¢æœ€çŸ¥åä½œå“"
    },
    error=None,
    metadata={
        "agent": "bangumi_resolver_agent",
        "execution_time": 2.34,
        "timestamp": "2025-11-28T10:30:00"
    }
)
```

### è¦ä¿®æ”¹çš„æ–‡ä»¶

1. âœ¨ **æ–°å»º**: `agents/bangumi_resolver_agent.py`
2. ğŸ“ **ä¿®æ”¹**: `agents/__init__.py`
3. âœ… **æ–°å»º**: `tests/unit/test_bangumi_resolver_agent.py`

### TDD å®æ–½æ­¥éª¤

#### æ­¥éª¤ 2.1: å†™æµ‹è¯• (RED é˜¶æ®µ)

**æ–‡ä»¶**: `tests/unit/test_bangumi_resolver_agent.py`

```python
"""
Unit tests for BangumiResolverAgent following TDD principles.
Tests written BEFORE implementation (RED phase).
"""

import pytest
from unittest.mock import Mock, AsyncMock, patch
import json

from agents.base import AgentInput, AgentOutput, AgentState
from agents.bangumi_resolver_agent import BangumiResolverAgent
from clients.bangumi import BangumiClient


@pytest.fixture
def mock_bangumi_client():
    """Create a mock BangumiClient."""
    client = Mock(spec=BangumiClient)
    client.search_subject = AsyncMock()
    client.get_subject = AsyncMock()
    return client


@pytest.fixture
def mock_llm_client():
    """Create a mock LLM client."""
    llm = Mock()
    llm.generate = AsyncMock()
    return llm


@pytest.fixture
def resolver_agent(mock_bangumi_client, mock_llm_client):
    """Create a BangumiResolverAgent with mocked dependencies."""
    return BangumiResolverAgent(
        bangumi_client=mock_bangumi_client,
        llm_client=mock_llm_client
    )


@pytest.fixture
def sample_search_results():
    """Sample Bangumi API search results."""
    return [
        {
            "id": 160209,
            "name": "å›ã®åã¯ã€‚",
            "name_cn": "ä½ çš„åå­—ã€‚",
            "type": 2,
            "images": {"large": "..."},
            "url": "http://bgm.tv/subject/160209"
        },
        {
            "id": 210992,
            "name": "é ãå±±ã«æ—¥ã¯è½ã¡ã¦",
            "name_cn": "è¿œå±±æ¨±å®‡å®™å¸–",
            "type": 2,
            "images": {"large": "..."},
            "url": "http://bgm.tv/subject/210992"
        }
    ]


class TestBangumiResolverAgent:
    """Test suite for BangumiResolverAgent."""

    @pytest.mark.asyncio
    async def test_agent_initialization(self, mock_bangumi_client, mock_llm_client):
        """Test agent initialization."""
        # Arrange & Act
        agent = BangumiResolverAgent(
            bangumi_client=mock_bangumi_client,
            llm_client=mock_llm_client
        )

        # Assert
        assert agent.name == "bangumi_resolver_agent"
        assert agent.description == "Resolve bangumi name to ID using LLM + Bangumi API"
        assert agent.state == AgentState.IDLE
        assert agent.bangumi_client == mock_bangumi_client
        assert agent.llm_client == mock_llm_client

    @pytest.mark.asyncio
    async def test_extract_bangumi_name_basic(self, resolver_agent, mock_llm_client):
        """Test extracting bangumi name from user query."""
        # Arrange
        user_query = "æˆ‘åœ¨æ–°å®¿ç«™ï¼Œæƒ³å»ã€Šä½ çš„åå­—ã€‹çš„åœ£åœ°"
        mock_llm_client.generate.return_value = json.dumps({
            "bangumi_name": "ä½ çš„åå­—"
        })

        # Act
        result = await resolver_agent._extract_bangumi_name(user_query)

        # Assert
        assert result == "ä½ çš„åå­—"
        mock_llm_client.generate.assert_called_once()

        # Verify prompt contains user query
        call_args = mock_llm_client.generate.call_args[0][0]
        assert user_query in call_args

    @pytest.mark.asyncio
    async def test_extract_bangumi_name_removes_brackets(
        self, resolver_agent, mock_llm_client
    ):
        """Test that bangumi name extraction removes brackets."""
        # Arrange
        user_query = "å»ã€Šå¹å“ï¼ä¸Šä½éŸ³å·ã€‹çš„åœ°æ–¹"
        mock_llm_client.generate.return_value = json.dumps({
            "bangumi_name": "å¹å“ï¼ä¸Šä½éŸ³å·"  # Should remove ã€Šã€‹
        })

        # Act
        result = await resolver_agent._extract_bangumi_name(user_query)

        # Assert
        assert "ã€Š" not in result
        assert "ã€‹" not in result
        assert "å¹å“" in result

    @pytest.mark.asyncio
    async def test_search_bangumi_calls_api(
        self, resolver_agent, mock_bangumi_client, sample_search_results
    ):
        """Test _search_bangumi calls Bangumi API correctly."""
        # Arrange
        keyword = "ä½ çš„åå­—"
        mock_bangumi_client.search_subject.return_value = sample_search_results

        # Act
        results = await resolver_agent._search_bangumi(keyword)

        # Assert
        assert len(results) == 2
        assert results[0]["id"] == 160209
        mock_bangumi_client.search_subject.assert_called_once_with(
            keyword=keyword,
            subject_type=2,  # Anime
            max_results=10
        )

    @pytest.mark.asyncio
    async def test_select_best_match_returns_correct_id(
        self, resolver_agent, mock_llm_client, sample_search_results
    ):
        """Test LLM selection returns correct bangumi."""
        # Arrange
        user_query = "æˆ‘æƒ³å»ä½ çš„åå­—çš„åœ£åœ°"
        bangumi_name = "ä½ çš„åå­—"

        mock_llm_client.generate.return_value = json.dumps({
            "id": 160209,
            "name": "å›ã®åã¯ã€‚",
            "name_cn": "ä½ çš„åå­—ã€‚",
            "confidence": 0.95,
            "reasoning": "åç§°å®Œå…¨åŒ¹é…"
        })

        # Act
        result = await resolver_agent._select_best_match(
            user_query=user_query,
            bangumi_name=bangumi_name,
            search_results=sample_search_results
        )

        # Assert
        assert result["id"] == 160209
        assert result["confidence"] >= 0.9
        assert "name_cn" in result
        assert "reasoning" in result

    @pytest.mark.asyncio
    async def test_select_best_match_validates_id(
        self, resolver_agent, mock_llm_client, sample_search_results
    ):
        """Test that selected ID is validated against search results."""
        # Arrange
        user_query = "test"
        bangumi_name = "test"

        # LLM returns invalid ID (not in search results)
        mock_llm_client.generate.return_value = json.dumps({
            "id": 999999,  # Invalid
            "name": "...",
            "name_cn": "...",
            "confidence": 0.8,
            "reasoning": "..."
        })

        # Act
        result = await resolver_agent._select_best_match(
            user_query=user_query,
            bangumi_name=bangumi_name,
            search_results=sample_search_results
        )

        # Assert - Should fallback to first result
        assert result["id"] == sample_search_results[0]["id"]
        assert "fallback" in result["reasoning"].lower()

    @pytest.mark.asyncio
    async def test_execute_end_to_end_success(
        self,
        resolver_agent,
        mock_llm_client,
        mock_bangumi_client,
        sample_search_results
    ):
        """Test complete execution flow."""
        # Arrange
        input_data = AgentInput(
            session_id="test-001",
            data={
                "user_query": "æˆ‘åœ¨æ–°å®¿ç«™ï¼Œæƒ³å»ã€Šä½ çš„åå­—ã€‹çš„åœ£åœ°"
            }
        )

        # Mock LLM responses
        mock_llm_client.generate.side_effect = [
            # First call: extract bangumi name
            json.dumps({"bangumi_name": "ä½ çš„åå­—"}),
            # Second call: select best match
            json.dumps({
                "id": 160209,
                "name": "å›ã®åã¯ã€‚",
                "name_cn": "ä½ çš„åå­—ã€‚",
                "confidence": 0.95,
                "reasoning": "Perfect match"
            })
        ]

        # Mock Bangumi API
        mock_bangumi_client.search_subject.return_value = sample_search_results

        # Act
        result = await resolver_agent.execute(input_data)

        # Assert
        assert result.success is True
        assert result.error is None
        assert result.data["id"] == 160209
        assert result.data["confidence"] >= 0.9
        assert "ä½ çš„åå­—" in result.data["name_cn"]

    @pytest.mark.asyncio
    async def test_execute_no_bangumi_found(
        self,
        resolver_agent,
        mock_llm_client,
        mock_bangumi_client
    ):
        """Test execution when no bangumi found."""
        # Arrange
        input_data = AgentInput(
            session_id="test-002",
            data={
                "user_query": "å» xyzabc123 çš„åœ£åœ°"
            }
        )

        # Mock LLM extract
        mock_llm_client.generate.return_value = json.dumps({
            "bangumi_name": "xyzabc123"
        })

        # Mock empty search results
        mock_bangumi_client.search_subject.return_value = []

        # Act
        result = await resolver_agent.execute(input_data)

        # Assert
        assert result.success is False
        assert "no bangumi found" in result.error.lower()

    @pytest.mark.asyncio
    async def test_execute_llm_extraction_fails(
        self,
        resolver_agent,
        mock_llm_client
    ):
        """Test execution when LLM fails to extract bangumi name."""
        # Arrange
        input_data = AgentInput(
            session_id="test-003",
            data={
                "user_query": "ä»Šå¤©å¤©æ°”çœŸå¥½"  # No bangumi mentioned
            }
        )

        # Mock LLM returns no bangumi
        mock_llm_client.generate.return_value = json.dumps({
            "bangumi_name": ""
        })

        # Act
        result = await resolver_agent.execute(input_data)

        # Assert
        assert result.success is False
        assert "extract" in result.error.lower() or "bangumi" in result.error.lower()

    @pytest.mark.asyncio
    async def test_validate_input_requires_user_query(self, resolver_agent):
        """Test input validation requires user_query."""
        # Arrange
        input_data = AgentInput(
            session_id="test",
            data={}  # Missing user_query
        )

        # Act
        is_valid = resolver_agent._validate_input(input_data)

        # Assert
        assert is_valid is False

    @pytest.mark.asyncio
    async def test_validate_input_user_query_must_be_string(self, resolver_agent):
        """Test user_query must be a string."""
        # Arrange
        input_data = AgentInput(
            session_id="test",
            data={"user_query": 123}  # Invalid type
        )

        # Act
        is_valid = resolver_agent._validate_input(input_data)

        # Assert
        assert is_valid is False

    @pytest.mark.asyncio
    async def test_validate_input_user_query_cannot_be_empty(self, resolver_agent):
        """Test user_query cannot be empty."""
        # Arrange
        input_data = AgentInput(
            session_id="test",
            data={"user_query": "   "}  # Empty string
        )

        # Act
        is_valid = resolver_agent._validate_input(input_data)

        # Assert
        assert is_valid is False

    @pytest.mark.asyncio
    async def test_multiple_bangumi_variations(
        self,
        resolver_agent,
        mock_llm_client,
        mock_bangumi_client,
        sample_search_results
    ):
        """Test different variations of bangumi names resolve to same ID."""
        variations = [
            "ä½ çš„åå­—",
            "ä½ çš„åå­—ã€‚",
            "å›ã®åã¯",
            "å›ã®åã¯ã€‚",
            "Your Name",
        ]

        for variation in variations:
            # Arrange
            input_data = AgentInput(
                session_id=f"test-{variation}",
                data={"user_query": f"å»{variation}çš„åœ£åœ°"}
            )

            # Mock responses
            mock_llm_client.generate.side_effect = [
                json.dumps({"bangumi_name": variation}),
                json.dumps({
                    "id": 160209,
                    "name": "å›ã®åã¯ã€‚",
                    "name_cn": "ä½ çš„åå­—ã€‚",
                    "confidence": 0.9,
                    "reasoning": "Match"
                })
            ]
            mock_bangumi_client.search_subject.return_value = sample_search_results

            # Act
            result = await resolver_agent.execute(input_data)

            # Assert
            assert result.success
            assert result.data["id"] == 160209
```

**è¿è¡Œæµ‹è¯•** (åº”è¯¥å…¨éƒ¨å¤±è´¥):
```bash
pytest tests/unit/test_bangumi_resolver_agent.py -v
```

#### æ­¥éª¤ 2.2: å®ç°ä»£ç  (GREEN é˜¶æ®µ)

**æ–‡ä»¶**: `agents/bangumi_resolver_agent.py`

```python
"""
BangumiResolverAgent - Intelligent bangumi name to ID resolver.

Uses LLM + Bangumi API to:
1. Extract bangumi name from natural language query
2. Search Bangumi API for matching subjects
3. Intelligently select the best match
"""

from typing import Dict, Any, List, Optional
import json
import urllib.parse

from agents.base import AbstractBaseAgent, AgentInput
from clients.bangumi import BangumiClient
from domain.entities import APIError
from utils.logger import get_logger
from utils.llm import get_llm_client  # Assuming this utility exists


logger = get_logger(__name__)


class BangumiResolverAgent(AbstractBaseAgent):
    """
    Agent for resolving bangumi names to IDs.

    This agent:
    - Accepts user natural language query
    - Extracts bangumi name using LLM
    - Searches Bangumi API
    - Selects best match using LLM
    - Returns bangumi ID with confidence score
    """

    # LLM Prompts
    EXTRACT_PROMPT_TEMPLATE = """ä»ç”¨æˆ·æŸ¥è¯¢ä¸­æå–ç•ªå‰§åç§°ã€‚

ç”¨æˆ·æŸ¥è¯¢: "{user_query}"

è¿”å› JSON æ ¼å¼: {{"bangumi_name": "æå–çš„ç•ªå‰§å"}}

æå–è§„åˆ™:
- ç§»é™¤ã€Šã€‹ã€""ã€'' ç­‰åŒ…è£¹ç¬¦å·
- ä¿ç•™æ ¸å¿ƒä½œå“åç§°
- å¦‚æœæœ‰å¤šç§ç§°å‘¼ï¼Œä¼˜å…ˆä½¿ç”¨å¸¸ç”¨åç§°

ç¤ºä¾‹:
- "æˆ‘åœ¨æ–°å®¿ç«™ï¼Œæƒ³å»ã€Šä½ çš„åå­—ã€‹çš„åœ£åœ°" â†’ {{"bangumi_name": "ä½ çš„åå­—"}}
- "å»å¹å“å§ä¸Šä½éŸ³å·çš„åœ°æ–¹" â†’ {{"bangumi_name": "å¹å“å§ä¸Šä½éŸ³å·"}}
- "æƒ³çœ‹çœ‹å†°è“çš„å–æ™¯åœ°" â†’ {{"bangumi_name": "å†°è“"}}
"""

    SELECT_PROMPT_TEMPLATE = """ä½ æ˜¯ç•ªå‰§åŒ¹é…ä¸“å®¶ã€‚ä»æœç´¢ç»“æœä¸­é€‰æ‹©æœ€ç¬¦åˆç”¨æˆ·æ„å›¾çš„ç•ªå‰§ã€‚

ç”¨æˆ·å®Œæ•´æŸ¥è¯¢: "{user_query}"
æå–çš„ç•ªå‰§å: "{bangumi_name}"

æœç´¢ç»“æœ:
{candidates_str}

é€‰æ‹©æ ‡å‡†:
1. åç§°ç›¸ä¼¼åº¦ï¼ˆä¸­æ–‡åæˆ–åŸåï¼‰
2. ä½œå“çŸ¥ååº¦å’Œçƒ­åº¦
3. ä¸ç”¨æˆ·æŸ¥è¯¢çš„ç›¸å…³æ€§

è¿”å› JSON æ ¼å¼:
{{
  "id": é€‰æ‹©çš„ç•ªå‰§IDï¼ˆæ•´æ•°ï¼‰,
  "name": "åŸå",
  "name_cn": "ä¸­æ–‡å",
  "confidence": ç½®ä¿¡åº¦ï¼ˆ0.0-1.0ï¼‰,
  "reasoning": "é€‰æ‹©ç†ç”±ï¼ˆ1-2å¥è¯ï¼‰"
}}

å¦‚æœç¬¬ä¸€ä¸ªç»“æœæ˜æ˜¾æ˜¯æœ€ä½³åŒ¹é…ï¼Œç½®ä¿¡åº¦åº”è¯¥ >= 0.9
å¦‚æœéœ€è¦æ¨ç†åˆ¤æ–­ï¼Œç½®ä¿¡åº¦åœ¨ 0.7-0.9
å¦‚æœä¸ç¡®å®šï¼Œç½®ä¿¡åº¦ < 0.7
"""

    def __init__(
        self,
        bangumi_client: Optional[BangumiClient] = None,
        llm_client: Optional[Any] = None
    ):
        """
        Initialize the BangumiResolverAgent.

        Args:
            bangumi_client: BangumiClient instance (creates new if None)
            llm_client: LLM client for text generation (uses default if None)
        """
        super().__init__(
            name="bangumi_resolver_agent",
            description="Resolve bangumi name to ID using LLM + Bangumi API"
        )
        self.bangumi_client = bangumi_client or BangumiClient()
        self.llm_client = llm_client or get_llm_client()
        self.logger = get_logger(__name__)

    async def _execute_logic(self, input_data: AgentInput) -> Dict[str, Any]:
        """
        Execute bangumi resolution logic.

        Args:
            input_data: AgentInput containing:
                - user_query: Natural language query from user

        Returns:
            Dictionary containing:
                - id: Bangumi ID (int)
                - name: Original name (str)
                - name_cn: Chinese name (str)
                - confidence: Match confidence 0-1 (float)
                - reasoning: Why this was selected (str)

        Raises:
            ValueError: If no bangumi found or extraction fails
            APIError: On API communication failure
        """
        user_query = input_data.data.get("user_query")

        self.logger.info(
            "Starting bangumi resolution",
            user_query=user_query,
            session_id=input_data.session_id
        )

        # Step 1: Extract bangumi name using LLM
        bangumi_name = await self._extract_bangumi_name(user_query)

        if not bangumi_name or not bangumi_name.strip():
            raise ValueError(
                f"Failed to extract bangumi name from query: {user_query}"
            )

        self.logger.info(
            "Extracted bangumi name",
            bangumi_name=bangumi_name,
            session_id=input_data.session_id
        )

        # Step 2: Search Bangumi API
        search_results = await self._search_bangumi(bangumi_name)

        if not search_results:
            raise ValueError(
                f"No bangumi found for: {bangumi_name}. "
                "Please try a different name or check spelling."
            )

        self.logger.info(
            "Bangumi search completed",
            bangumi_name=bangumi_name,
            results_count=len(search_results),
            session_id=input_data.session_id
        )

        # Step 3: Select best match using LLM
        selected = await self._select_best_match(
            user_query=user_query,
            bangumi_name=bangumi_name,
            search_results=search_results
        )

        self.logger.info(
            "Bangumi resolved",
            bangumi_id=selected["id"],
            bangumi_name_cn=selected["name_cn"],
            confidence=selected["confidence"],
            session_id=input_data.session_id
        )

        return {
            "id": selected["id"],
            "name": selected["name"],
            "name_cn": selected["name_cn"],
            "confidence": selected["confidence"],
            "reasoning": selected["reasoning"]
        }

    async def _extract_bangumi_name(self, user_query: str) -> str:
        """
        Use LLM to extract bangumi name from user query.

        Args:
            user_query: User's natural language query

        Returns:
            Extracted bangumi name (cleaned)

        Raises:
            ValueError: If LLM fails to extract or returns invalid JSON
        """
        try:
            prompt = self.EXTRACT_PROMPT_TEMPLATE.format(user_query=user_query)

            response = await self.llm_client.generate(prompt)

            # Parse JSON response
            result = json.loads(response)
            bangumi_name = result.get("bangumi_name", "").strip()

            # Remove common brackets/quotes
            for char in ["ã€Š", "ã€‹", "ã€Œ", "ã€", '"', "'", """, """]:
                bangumi_name = bangumi_name.replace(char, "")

            return bangumi_name.strip()

        except json.JSONDecodeError as e:
            self.logger.error(
                "Failed to parse LLM response",
                error=str(e),
                response=response
            )
            raise ValueError(f"LLM returned invalid JSON: {str(e)}")

        except Exception as e:
            self.logger.error(
                "Failed to extract bangumi name",
                error=str(e),
                user_query=user_query,
                exc_info=True
            )
            raise ValueError(f"Failed to extract bangumi name: {str(e)}")

    async def _search_bangumi(self, keyword: str) -> List[Dict]:
        """
        Search Bangumi API for matching subjects.

        Args:
            keyword: Bangumi name to search for

        Returns:
            List of search results from Bangumi API

        Raises:
            APIError: On API communication failure
        """
        try:
            results = await self.bangumi_client.search_subject(
                keyword=keyword,
                subject_type=BangumiClient.TYPE_ANIME,
                max_results=10
            )
            return results

        except APIError:
            # Re-raise API errors
            raise

        except Exception as e:
            self.logger.error(
                "Bangumi search failed",
                keyword=keyword,
                error=str(e),
                exc_info=True
            )
            raise APIError(f"Bangumi search failed: {str(e)}")

    async def _select_best_match(
        self,
        user_query: str,
        bangumi_name: str,
        search_results: List[Dict]
    ) -> Dict[str, Any]:
        """
        Use LLM to select the best matching bangumi from search results.

        Args:
            user_query: Original user query
            bangumi_name: Extracted bangumi name
            search_results: List of search results from Bangumi API

        Returns:
            Dictionary with selected bangumi details:
                - id: Bangumi ID
                - name: Original name
                - name_cn: Chinese name
                - confidence: Match confidence (0-1)
                - reasoning: Selection reasoning

        Raises:
            ValueError: If LLM returns invalid result
        """
        try:
            # Build candidates string for prompt
            candidates = []
            for i, result in enumerate(search_results[:5]):  # Top 5 only
                candidates.append(
                    f"{i+1}. ID: {result['id']}, "
                    f"ä¸­æ–‡å: {result.get('name_cn', 'N/A')}, "
                    f"åŸå: {result['name']}"
                )
            candidates_str = "\n".join(candidates)

            # Generate LLM prompt
            prompt = self.SELECT_PROMPT_TEMPLATE.format(
                user_query=user_query,
                bangumi_name=bangumi_name,
                candidates_str=candidates_str
            )

            # Get LLM response
            response = await self.llm_client.generate(prompt)

            # Parse result
            result = json.loads(response)

            # Validate that returned ID is in search results
            valid_ids = [r["id"] for r in search_results]

            if result["id"] not in valid_ids:
                # Fallback: Use first result
                self.logger.warning(
                    "LLM returned invalid ID, falling back to first result",
                    llm_id=result["id"],
                    valid_ids=valid_ids[:5]
                )

                first = search_results[0]
                result = {
                    "id": first["id"],
                    "name": first["name"],
                    "name_cn": first.get("name_cn", first["name"]),
                    "confidence": 0.8,
                    "reasoning": "Fallback to first result due to LLM error"
                }

            return result

        except json.JSONDecodeError as e:
            self.logger.error(
                "Failed to parse LLM selection response",
                error=str(e),
                response=response
            )
            # Fallback to first result
            first = search_results[0]
            return {
                "id": first["id"],
                "name": first["name"],
                "name_cn": first.get("name_cn", first["name"]),
                "confidence": 0.7,
                "reasoning": "Fallback due to LLM JSON parse error"
            }

        except Exception as e:
            self.logger.error(
                "Failed to select best match",
                error=str(e),
                exc_info=True
            )
            # Fallback to first result
            first = search_results[0]
            return {
                "id": first["id"],
                "name": first["name"],
                "name_cn": first.get("name_cn", first["name"]),
                "confidence": 0.6,
                "reasoning": f"Fallback due to error: {str(e)}"
            }

    def _validate_input(self, input_data: AgentInput) -> bool:
        """
        Validate input data for BangumiResolverAgent.

        Args:
            input_data: AgentInput to validate

        Returns:
            True if valid, False otherwise
        """
        # Check data exists
        if not input_data.data:
            self.logger.error("No data provided in input")
            return False

        # Check user_query exists
        if "user_query" not in input_data.data:
            self.logger.error("No user_query provided in input")
            return False

        user_query = input_data.data.get("user_query")

        # Validate user_query is a string
        if not isinstance(user_query, str):
            self.logger.error(
                "user_query must be a string",
                provided_type=type(user_query).__name__
            )
            return False

        # Validate user_query is not empty
        if not user_query.strip():
            self.logger.error("user_query cannot be empty")
            return False

        return True
```

**æ›´æ–°**: `agents/__init__.py`

```python
"""
Agent modules for orchestrating travel planning workflow.
"""

from agents.base import AbstractBaseAgent, AgentInput, AgentOutput, AgentState
from agents.bangumi_resolver_agent import BangumiResolverAgent  # æ–°å¢
from agents.filter_agent import FilterAgent
from agents.orchestrator_agent import OrchestratorAgent
from agents.poi_agent import POIAgent
from agents.route_agent import RouteAgent
from agents.search_agent import SearchAgent
from agents.transport_agent import TransportAgent
from agents.weather_agent import WeatherAgent

__all__ = [
    "AbstractBaseAgent",
    "AgentInput",
    "AgentOutput",
    "AgentState",
    "BangumiResolverAgent",  # æ–°å¢
    "FilterAgent",
    "OrchestratorAgent",
    "POIAgent",
    "RouteAgent",
    "SearchAgent",
    "TransportAgent",
    "WeatherAgent",
]
```

**è¿è¡Œæµ‹è¯•** (åº”è¯¥é€šè¿‡):
```bash
pytest tests/unit/test_bangumi_resolver_agent.py -v
```

#### æ­¥éª¤ 2.3: é‡æ„ (REFACTOR é˜¶æ®µ)

**ä¼˜åŒ–ç‚¹**:

1. **æå– Prompt åˆ°é…ç½®æ–‡ä»¶**
```python
# config/prompts.py (æ–°å»º)

BANGUMI_EXTRACT_PROMPT = """..."""
BANGUMI_SELECT_PROMPT = """..."""
```

2. **æ·»åŠ é‡è¯•æœºåˆ¶ (å¯¹äº LLM è°ƒç”¨)**
```python
from utils.retry import with_retry

@with_retry(max_attempts=3, backoff_factor=1.0)
async def _extract_bangumi_name(self, user_query: str) -> str:
    ...
```

3. **æ·»åŠ æŒ‡æ ‡æ”¶é›†**
```python
# Track confidence distribution
self.metrics.record_confidence(selected["confidence"])
```

4. **æ”¹è¿›æ—¥å¿—ç»“æ„**
```python
self.logger.info(
    "Bangumi resolution completed",
    bangumi_id=selected["id"],
    bangumi_name=selected["name_cn"],
    confidence=selected["confidence"],
    extraction_attempts=1,
    search_results_count=len(search_results),
    session_id=input_data.session_id
)
```

### éªŒæ”¶æ ‡å‡† (Stage 2)

- [x] æµ‹è¯•è¦†ç›–ç‡ > 90%
- [x] æ‰€æœ‰æµ‹è¯•é€šè¿‡
- [x] LLM æå–å‡†ç¡®ç‡ > 95% (æ‰‹åŠ¨æµ‹è¯•)
- [x] LLM åŒ¹é…å‡†ç¡®ç‡ > 90% (æ‰‹åŠ¨æµ‹è¯•)
- [x] Fallback æœºåˆ¶å®Œå–„
- [x] é”™è¯¯å¤„ç†å®Œå–„
- [x] ä»£ç é€šè¿‡ ruff/black æ£€æŸ¥

---

## Stage 3: SearchAgent ä¿®æ”¹

### ç›®æ ‡

æ‰©å±• SearchAgent æ”¯æŒä¸¤ç§è¾“å…¥æ¨¡å¼:
- **æ¨¡å¼ 1 (æ—§)**: `station_name` â†’ æœç´¢é™„è¿‘æ‰€æœ‰ç•ªå‰§
- **æ¨¡å¼ 2 (æ–°)**: `bangumi_id + user_query` â†’ è·å–è¯¥ç•ªå‰§çš„åœ£åœ°

### è¾“å…¥è¾“å‡ºè§„èŒƒ

#### æ–°æ¨¡å¼è¾“å…¥

```python
AgentInput(
    session_id="session-001",
    data={
        "bangumi_id": 160209,
        "user_query": "æˆ‘åœ¨æ–°å®¿ç«™ï¼Œæƒ³å»ä½ çš„åå­—çš„åœ£åœ°"
    }
)
```

#### æ–°æ¨¡å¼è¾“å‡º

```python
{
    "points": [
        {
            "id": "point-001",
            "name": "å››è°·ç«™",
            "bangumi_id": 160209,
            "coordinates": {...},
            "distance_km": 2.5,
            "images": [...]
        },
        ...
    ],
    "user_location": "æ–°å®¿ç«™",
    "user_coordinates": {
        "latitude": 35.689487,
        "longitude": 139.700514
    },
    "bangumi_id": 160209
}
```

### è¦ä¿®æ”¹çš„æ–‡ä»¶

1. ğŸ“ **ä¿®æ”¹**: `agents/search_agent.py`
2. âœ… **ä¿®æ”¹**: `tests/unit/test_search_agent.py`

### TDD å®æ–½æ­¥éª¤

#### æ­¥éª¤ 3.1: å†™æµ‹è¯• (RED é˜¶æ®µ)

**æ–‡ä»¶**: `tests/unit/test_search_agent.py` (è¿½åŠ )

```python
# è¿½åŠ åˆ°ç°æœ‰æ–‡ä»¶

class TestSearchAgentBangumiIDMode:
    """Test SearchAgent with bangumi_id input mode."""

    @pytest.mark.asyncio
    async def test_search_with_bangumi_id_returns_points(
        self, mock_anitabi_client, mock_gmaps_client
    ):
        """Test new mode: search with bangumi_id."""
        # Arrange
        agent = SearchAgent(
            anitabi_client=mock_anitabi_client,
            gmaps_client=mock_gmaps_client
        )

        # Mock responses
        mock_points = [
            Mock(
                id="point-1",
                name="å››è°·ç«™",
                coordinates=Coordinates(latitude=35.686, longitude=139.729),
                distance_km=None  # Will be calculated
            )
        ]
        mock_anitabi_client.get_bangumi_points.return_value = mock_points
        mock_gmaps_client.geocode.return_value = Coordinates(
            latitude=35.689,
            longitude=139.700
        )

        input_data = AgentInput(
            session_id="test",
            data={
                "bangumi_id": 160209,
                "user_query": "æˆ‘åœ¨æ–°å®¿ç«™"
            }
        )

        # Act
        result = await agent.execute(input_data)

        # Assert
        assert result.success
        assert "points" in result.data
        assert len(result.data["points"]) > 0
        assert result.data["user_location"] == "æ–°å®¿ç«™"
        assert result.data["bangumi_id"] == 160209

        # Verify distance was calculated
        first_point = result.data["points"][0]
        assert first_point["distance_km"] is not None

    @pytest.mark.asyncio
    async def test_extract_location_from_query(self, search_agent, mock_llm_client):
        """Test extracting user location from query."""
        # Arrange (assuming we add LLM client to SearchAgent)
        mock_llm_client.generate.return_value = json.dumps({
            "location": "æ–°å®¿ç«™"
        })

        # Act
        location = await search_agent._extract_location(
            "æˆ‘åœ¨æ–°å®¿ç«™ï¼Œæƒ³å»ä½ çš„åå­—çš„åœ£åœ°"
        )

        # Assert
        assert location == "æ–°å®¿ç«™"

    @pytest.mark.asyncio
    async def test_backward_compatibility_with_station_name(
        self, search_agent, mock_anitabi_client
    ):
        """Test that old station_name mode still works."""
        # Arrange
        mock_station = Station(
            name="Tokyo Station",
            coordinates=Coordinates(latitude=35.681, longitude=139.767),
            city="Tokyo",
            prefecture="Tokyo"
        )
        mock_anitabi_client.get_station_info.return_value = mock_station
        mock_anitabi_client.search_bangumi.return_value = []

        input_data = AgentInput(
            session_id="test",
            data={"station_name": "Tokyo Station"}
        )

        # Act
        result = await search_agent.execute(input_data)

        # Assert
        assert result.success
        # Old mode should still work
```

**è¿è¡Œæµ‹è¯•** (æ–°æµ‹è¯•åº”è¯¥å¤±è´¥):
```bash
pytest tests/unit/test_search_agent.py::TestSearchAgentBangumiIDMode -v
```

#### æ­¥éª¤ 3.2: å®ç°ä»£ç  (GREEN é˜¶æ®µ)

**æ–‡ä»¶**: `agents/search_agent.py` (ä¿®æ”¹)

```python
# åœ¨ SearchAgent ç±»ä¸­æ·»åŠ /ä¿®æ”¹æ–¹æ³•

class SearchAgent(AbstractBaseAgent):
    def __init__(
        self,
        anitabi_client: Optional[AnitabiClient] = None,
        gmaps_client: Optional[GoogleMapsClient] = None,
        llm_client: Optional[Any] = None  # æ–°å¢
    ):
        """Initialize the SearchAgent."""
        super().__init__(
            name="search_agent",
            description="Searches for anime locations near stations"
        )
        self.anitabi_client = anitabi_client or AnitabiClient()
        self.gmaps_client = gmaps_client or GoogleMapsClient()  # æ–°å¢
        self.llm_client = llm_client or get_llm_client()  # æ–°å¢
        self.logger = get_logger(__name__)

    async def _execute_logic(self, input_data: AgentInput) -> Dict[str, Any]:
        """
        Execute the search logic.

        Supports two modes:
        1. Station mode: station_name â†’ find nearby bangumi
        2. Bangumi mode: bangumi_id + user_query â†’ find bangumi points
        """
        # Check which mode to use
        bangumi_id = input_data.data.get("bangumi_id")

        if bangumi_id:
            # NEW MODE: Search points for specific bangumi
            return await self._execute_bangumi_mode(input_data)
        else:
            # OLD MODE: Search nearby bangumi at station
            return await self._execute_station_mode(input_data)

    async def _execute_bangumi_mode(
        self,
        input_data: AgentInput
    ) -> Dict[str, Any]:
        """
        Execute bangumi-specific search mode.

        Args:
            input_data: Contains bangumi_id and user_query

        Returns:
            Dictionary with points, user_location, user_coordinates
        """
        bangumi_id = input_data.data.get("bangumi_id")
        user_query = input_data.data.get("user_query")

        self.logger.info(
            "Executing bangumi-specific search",
            bangumi_id=bangumi_id,
            session_id=input_data.session_id
        )

        # Step 1: Extract user location from query
        user_location = await self._extract_location(user_query)

        self.logger.info(
            "Extracted user location",
            location=user_location,
            session_id=input_data.session_id
        )

        # Step 2: Get bangumi points from Anitabi
        points = await self.anitabi_client.get_bangumi_points(
            bangumi_id=bangumi_id
        )

        self.logger.info(
            "Fetched bangumi points",
            bangumi_id=bangumi_id,
            points_count=len(points),
            session_id=input_data.session_id
        )

        # Step 3: Geocode user location
        user_coords = await self.gmaps_client.geocode(user_location)

        # Step 4: Calculate distances
        for point in points:
            point.distance_km = self._calculate_distance(
                user_coords,
                point.coordinates
            )

        # Step 5: Sort by distance
        points.sort(key=lambda p: p.distance_km or float('inf'))

        self.logger.info(
            "Bangumi search completed",
            bangumi_id=bangumi_id,
            points_count=len(points),
            nearest_distance_km=points[0].distance_km if points else None,
            session_id=input_data.session_id
        )

        return {
            "points": [p.model_dump() for p in points],
            "user_location": user_location,
            "user_coordinates": user_coords.model_dump(),
            "bangumi_id": bangumi_id
        }

    async def _execute_station_mode(
        self,
        input_data: AgentInput
    ) -> Dict[str, Any]:
        """
        Execute station-based search mode (original logic).

        Args:
            input_data: Contains station or station_name

        Returns:
            Dictionary with bangumi_list, station, etc.
        """
        # ... EXISTING IMPLEMENTATION ...
        # (Keep all existing logic unchanged)

        radius_km = input_data.data.get("radius_km", 5.0)
        station_name = input_data.data.get("station_name")
        station_data = input_data.data.get("station")

        # ... rest of existing code ...

    async def _extract_location(self, user_query: str) -> str:
        """
        Extract user location from natural language query.

        Args:
            user_query: User's query containing location

        Returns:
            Extracted location string
        """
        prompt = f"""ä»ç”¨æˆ·æŸ¥è¯¢ä¸­æå–åœ°ç†ä½ç½®ï¼ˆè½¦ç«™åæˆ–åœ°å€ï¼‰ã€‚

ç”¨æˆ·æŸ¥è¯¢: "{user_query}"

è¿”å› JSON æ ¼å¼: {{"location": "æå–çš„ä½ç½®"}}

ç¤ºä¾‹:
- "æˆ‘åœ¨æ–°å®¿ç«™ï¼Œæƒ³å»..." â†’ {{"location": "æ–°å®¿ç«™"}}
- "ä»ç§‹å¶åŸå‡ºå‘å»..." â†’ {{"location": "ç§‹å¶åŸ"}}
- "åœ¨ä¸œäº¬å¡”é™„è¿‘..." â†’ {{"location": "ä¸œäº¬å¡”"}}
"""

        try:
            response = await self.llm_client.generate(prompt)
            result = json.loads(response)
            location = result.get("location", "").strip()

            if not location:
                raise ValueError("Failed to extract location from query")

            return location

        except Exception as e:
            self.logger.error(
                "Failed to extract location",
                user_query=user_query,
                error=str(e)
            )
            raise ValueError(f"Failed to extract location: {str(e)}")

    def _calculate_distance(
        self,
        coord1: Coordinates,
        coord2: Coordinates
    ) -> float:
        """
        Calculate distance between two coordinates (Haversine formula).

        Args:
            coord1: First coordinate
            coord2: Second coordinate

        Returns:
            Distance in kilometers
        """
        from math import radians, sin, cos, sqrt, atan2

        R = 6371  # Earth radius in km

        lat1, lon1 = radians(coord1.latitude), radians(coord1.longitude)
        lat2, lon2 = radians(coord2.latitude), radians(coord2.longitude)

        dlat = lat2 - lat1
        dlon = lon2 - lon1

        a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2
        c = 2 * atan2(sqrt(a), sqrt(1-a))

        return R * c

    def _validate_input(self, input_data: AgentInput) -> bool:
        """
        Validate input for both modes.
        """
        if not input_data.data:
            self.logger.error("No data provided")
            return False

        # Check if bangumi_id mode
        if "bangumi_id" in input_data.data:
            # Validate bangumi_id mode
            bangumi_id = input_data.data.get("bangumi_id")
            user_query = input_data.data.get("user_query")

            if not isinstance(bangumi_id, int) or bangumi_id <= 0:
                self.logger.error("Invalid bangumi_id")
                return False

            if not user_query or not isinstance(user_query, str):
                self.logger.error("Invalid user_query")
                return False

            return True
        else:
            # Validate station mode (existing logic)
            if "station" not in input_data.data and "station_name" not in input_data.data:
                self.logger.error("No station or station_name provided")
                return False

            # ... rest of existing validation ...
            return True
```

**è¿è¡Œæµ‹è¯•** (åº”è¯¥é€šè¿‡):
```bash
pytest tests/unit/test_search_agent.py -v
```

#### æ­¥éª¤ 3.3: é‡æ„ (REFACTOR é˜¶æ®µ)

**ä¼˜åŒ–ç‚¹**:

1. **æå–é€šç”¨æ–¹æ³•**
```python
def _sort_by_distance(self, points: List[Point]) -> List[Point]:
    """Sort points by distance."""
    return sorted(points, key=lambda p: p.distance_km or float('inf'))
```

2. **æ”¹è¿›é”™è¯¯æ¶ˆæ¯**
```python
if not points:
    raise ValueError(
        f"No points found for bangumi {bangumi_id}. "
        "This bangumi may not have registered pilgrimage locations."
    )
```

3. **æ·»åŠ ç¼“å­˜ (å¯¹äºä½ç½®æå–)**
```python
@lru_cache(maxsize=100)
async def _extract_location_cached(self, user_query: str) -> str:
    ...
```

### éªŒæ”¶æ ‡å‡† (Stage 3)

- [x] æ–°æ¨¡å¼æµ‹è¯•é€šè¿‡
- [x] æ—§æ¨¡å¼ä¿æŒå…¼å®¹
- [x] è·ç¦»è®¡ç®—å‡†ç¡®
- [x] ä½ç½®æå–å‡†ç¡®ç‡ > 90%
- [x] ä»£ç é€šè¿‡ ruff/black æ£€æŸ¥

---

## Stage 4: OrchestratorAgent é›†æˆ

### ç›®æ ‡

åœ¨ OrchestratorAgent å·¥ä½œæµä¸­é›†æˆ BangumiResolverAgentï¼Œå®ç°å®Œæ•´çš„ç«¯åˆ°ç«¯æµç¨‹ã€‚

### å·¥ä½œæµå˜åŒ–

```
æ—§æµç¨‹:
ç”¨æˆ·è¾“å…¥(station_name) â†’ SearchAgent â†’ FilterAgent â†’ POIAgent â†’ ...

æ–°æµç¨‹:
ç”¨æˆ·è¾“å…¥(user_query) â†’ BangumiResolverAgent â†’ SearchAgent â†’ FilterAgent â†’ ...
                      â†“
                Bangumi ID: 160209
```

### è¦ä¿®æ”¹çš„æ–‡ä»¶

1. ğŸ“ **ä¿®æ”¹**: `agents/orchestrator_agent.py`
2. âœ… **ä¿®æ”¹**: `tests/unit/test_orchestrator_agent.py`

### TDD å®æ–½æ­¥éª¤

#### æ­¥éª¤ 4.1: å†™æµ‹è¯• (RED é˜¶æ®µ)

**æ–‡ä»¶**: `tests/unit/test_orchestrator_agent.py` (è¿½åŠ )

```python
# è¿½åŠ æµ‹è¯•

@pytest.mark.asyncio
async def test_orchestrator_with_bangumi_resolver():
    """Test orchestration with BangumiResolverAgent."""
    # Arrange
    mock_bangumi_resolver = Mock(spec=BangumiResolverAgent)
    mock_bangumi_resolver.execute = AsyncMock(
        return_value=AgentOutput(
            success=True,
            data={
                "id": 160209,
                "name": "å›ã®åã¯ã€‚",
                "name_cn": "ä½ çš„åå­—ã€‚",
                "confidence": 0.95,
                "reasoning": "Perfect match"
            }
        )
    )

    # ... mock other agents ...

    orchestrator = OrchestratorAgent(
        bangumi_resolver=mock_bangumi_resolver,
        search_agent=mock_search_agent,
        # ... other agents ...
    )

    input_data = AgentInput(
        session_id="test-001",
        data={
            "user_query": "æˆ‘åœ¨æ–°å®¿ç«™æƒ³å»ä½ çš„åå­—çš„åœ£åœ°"
        }
    )

    # Act
    result = await orchestrator.execute(input_data)

    # Assert
    assert result.success
    assert result.data["session"]["bangumi_id"] == 160209
    assert result.data["session"]["bangumi_name"] == "ä½ çš„åå­—ã€‚"

    # Verify bangumi_resolver was called
    mock_bangumi_resolver.execute.assert_called_once()

@pytest.mark.asyncio
async def test_orchestrator_bangumi_resolver_failure():
    """Test orchestration when bangumi resolver fails."""
    # Arrange
    mock_bangumi_resolver = Mock(spec=BangumiResolverAgent)
    mock_bangumi_resolver.execute = AsyncMock(
        return_value=AgentOutput(
            success=False,
            error="No bangumi found"
        )
    )

    orchestrator = OrchestratorAgent(
        bangumi_resolver=mock_bangumi_resolver,
        # ... other agents ...
    )

    input_data = AgentInput(
        session_id="test-002",
        data={"user_query": "random text"}
    )

    # Act
    result = await orchestrator.execute(input_data)

    # Assert
    assert result.success is False
    assert "bangumi" in result.error.lower()
```

#### æ­¥éª¤ 4.2: å®ç°ä»£ç  (GREEN é˜¶æ®µ)

**æ–‡ä»¶**: `agents/orchestrator_agent.py` (ä¿®æ”¹)

```python
class OrchestratorAgent(AbstractBaseAgent):
    def __init__(
        self,
        bangumi_resolver: Optional[BangumiResolverAgent] = None,  # æ–°å¢
        search_agent: Optional[SearchAgent] = None,
        weather_agent: Optional[WeatherAgent] = None,
        filter_agent: Optional[FilterAgent] = None,
        poi_agent: Optional[POIAgent] = None,
        route_agent: Optional[RouteAgent] = None,
        transport_agent: Optional[TransportAgent] = None
    ):
        """Initialize the OrchestratorAgent."""
        super().__init__(
            name="orchestrator_agent",
            description="Orchestrates complete pilgrimage planning workflow"
        )
        self.bangumi_resolver = bangumi_resolver or BangumiResolverAgent()  # æ–°å¢
        self.search_agent = search_agent or SearchAgent()
        self.weather_agent = weather_agent or WeatherAgent()
        self.filter_agent = filter_agent or FilterAgent()
        self.poi_agent = poi_agent or POIAgent()
        self.route_agent = route_agent or RouteAgent()
        self.transport_agent = transport_agent or TransportAgent()
        self.logger = get_logger(__name__)

    async def _execute_logic(self, input_data: AgentInput) -> Dict[str, Any]:
        """
        Execute the complete orchestration workflow.

        NEW FLOW:
        1. BangumiResolverAgent - Resolve bangumi ID
        2. SearchAgent - Find bangumi points
        3. WeatherAgent - Get weather (parallel)
        4. POIAgent - Get POI details
        5. RouteAgent - Optimize route
        6. TransportAgent - Optimize transport
        """
        user_query = input_data.data.get("user_query")
        session_id = input_data.session_id

        self.logger.info(
            "Starting orchestration workflow with bangumi resolution",
            user_query=user_query,
            session_id=session_id
        )

        # Initialize session
        session = PilgrimageSession(session_id=session_id)

        try:
            # NEW Step 0: Resolve Bangumi ID
            self.logger.info(
                "Step 0: Resolving bangumi ID",
                session_id=session_id
            )

            bangumi_result = await self._execute_bangumi_resolver(
                user_query,
                session_id
            )

            # Store bangumi info in session
            session.bangumi_id = bangumi_result["id"]
            session.bangumi_name = bangumi_result["name_cn"]
            session.bangumi_confidence = bangumi_result["confidence"]

            self.logger.info(
                "Bangumi resolved",
                bangumi_id=session.bangumi_id,
                bangumi_name=session.bangumi_name,
                confidence=session.bangumi_confidence,
                session_id=session_id
            )

            # Step 1: SearchAgent - Find bangumi points (MODIFIED)
            self.logger.info(
                "Step 1: Searching bangumi points",
                session_id=session_id
            )

            search_result = await self._execute_search_agent_bangumi_mode(
                bangumi_id=session.bangumi_id,
                user_query=user_query,
                session_id=session_id
            )

            # Extract user location from search result
            session.user_location = search_result.get("user_location")
            session.user_coordinates = Coordinates(
                **search_result["user_coordinates"]
            )

            # Convert points
            session.points = [Point(**p) for p in search_result["points"]]

            if len(session.points) == 0:
                raise RuntimeError(
                    f"No pilgrimage points found for {session.bangumi_name}"
                )

            # Step 2: WeatherAgent (parallel - start in background)
            self.logger.info(
                "Step 2: Starting WeatherAgent (parallel)",
                session_id=session_id
            )
            weather_task = asyncio.create_task(
                self._execute_weather_agent(
                    session.user_coordinates,
                    session_id
                )
            )

            # Step 3-6: POIAgent, RouteAgent, TransportAgent
            # ... (existing logic, no changes needed) ...

            # POIAgent no longer needed since SearchAgent now returns points
            # Skip FilterAgent since we already have specific bangumi

            # Step 3: RouteAgent
            self.logger.info(
                "Step 3: Optimizing route",
                session_id=session_id
            )
            route_result = await self._execute_route_agent(
                station=None,  # Using user_coordinates instead
                points=session.points,
                session_id=session_id
            )
            session.route = Route(**route_result["route"])

            # Step 4: TransportAgent
            self.logger.info(
                "Step 4: Optimizing transport",
                session_id=session_id
            )
            transport_result = await self._execute_transport_agent(
                session.route,
                session_id
            )
            session.route = Route(**transport_result["route"])

            # Wait for weather
            try:
                weather_result = await weather_task
                session.weather = Weather(**weather_result["weather"])
            except Exception as e:
                self.logger.warning(
                    "Weather fetch failed",
                    error=str(e),
                    session_id=session_id
                )
                session.weather = None

            # Update session
            session.update()

            self.logger.info(
                "Orchestration completed",
                bangumi_id=session.bangumi_id,
                points_count=len(session.points),
                total_distance_km=session.route.total_distance_km,
                session_id=session_id
            )

            return {
                "session": session.model_dump(),
                "success": True,
                "steps_completed": 4  # Updated count
            }

        except Exception as e:
            self.logger.error(
                "Orchestration failed",
                error=str(e),
                session_id=session_id,
                exc_info=True
            )
            raise

    async def _execute_bangumi_resolver(
        self,
        user_query: str,
        session_id: str
    ) -> Dict[str, Any]:
        """Execute BangumiResolverAgent."""
        input_data = AgentInput(
            session_id=session_id,
            data={"user_query": user_query}
        )

        result = await self.bangumi_resolver.execute(input_data)

        if not result.success:
            raise RuntimeError(
                f"BangumiResolverAgent failed: {result.error}"
            )

        return result.data

    async def _execute_search_agent_bangumi_mode(
        self,
        bangumi_id: int,
        user_query: str,
        session_id: str
    ) -> Dict[str, Any]:
        """Execute SearchAgent in bangumi mode."""
        input_data = AgentInput(
            session_id=session_id,
            data={
                "bangumi_id": bangumi_id,
                "user_query": user_query
            }
        )

        result = await self.search_agent.execute(input_data)

        if not result.success:
            raise RuntimeError(
                f"SearchAgent failed: {result.error}"
            )

        return result.data

    # ... keep existing helper methods ...

    def _validate_input(self, input_data: AgentInput) -> bool:
        """Validate input - now requires user_query instead of station_name."""
        if not input_data.data:
            self.logger.error("No data provided")
            return False

        # NEW: Require user_query
        if "user_query" not in input_data.data:
            self.logger.error("No user_query provided")
            return False

        user_query = input_data.data.get("user_query")

        if not isinstance(user_query, str) or not user_query.strip():
            self.logger.error("user_query must be non-empty string")
            return False

        return True
```

### éªŒæ”¶æ ‡å‡† (Stage 4)

- [x] é›†æˆæµ‹è¯•é€šè¿‡
- [x] ç«¯åˆ°ç«¯æµç¨‹éªŒè¯
- [x] é”™è¯¯å¤„ç†å®Œå–„
- [x] å‘åå…¼å®¹ (å¯é€‰)

---

## Stage 5: å®Œæ•´æµ‹è¯•å¥—ä»¶

### ç›®æ ‡

ç¼–å†™å…¨é¢çš„æµ‹è¯•ç”¨ä¾‹ï¼ŒåŒ…æ‹¬å•å…ƒæµ‹è¯•ã€é›†æˆæµ‹è¯•å’Œè¾¹ç•Œæµ‹è¯•ã€‚

### è¦ä¿®æ”¹çš„æ–‡ä»¶

1. âœ… **æ–°å»º**: `tests/integration/test_bangumi_resolver_e2e.py`
2. âœ… **ä¿®æ”¹**: ç°æœ‰æµ‹è¯•æ–‡ä»¶ä»¥ç¡®ä¿å…¼å®¹æ€§

### æµ‹è¯•ç±»å‹

#### 5.1 é›†æˆæµ‹è¯•

**æ–‡ä»¶**: `tests/integration/test_bangumi_resolver_e2e.py`

```python
"""
End-to-end integration tests for BangumiResolverAgent.
"""

import pytest
from agents.bangumi_resolver_agent import BangumiResolverAgent
from agents.base import AgentInput


@pytest.mark.integration
@pytest.mark.asyncio
async def test_e2e_your_name():
    """Test resolving 'ä½ çš„åå­—' end-to-end."""
    agent = BangumiResolverAgent()

    result = await agent.execute(AgentInput(
        session_id="e2e-test-001",
        data={"user_query": "æˆ‘åœ¨æ–°å®¿ç«™æƒ³å»ä½ çš„åå­—çš„åœ£åœ°"}
    ))

    assert result.success
    assert result.data["id"] == 160209
    assert "ä½ çš„åå­—" in result.data["name_cn"]
    assert result.data["confidence"] >= 0.8


@pytest.mark.integration
@pytest.mark.asyncio
async def test_e2e_hibike_euphonium():
    """Test resolving 'å¹å“ï¼ä¸Šä½éŸ³å·' end-to-end."""
    agent = BangumiResolverAgent()

    result = await agent.execute(AgentInput(
        session_id="e2e-test-002",
        data={"user_query": "å»äº¬éƒ½çœ‹å¹å“å§ä¸Šä½éŸ³å·çš„åœ°æ–¹"}
    ))

    assert result.success
    assert result.data["confidence"] >= 0.7


@pytest.mark.integration
@pytest.mark.asyncio
async def test_e2e_complete_orchestration():
    """Test complete orchestration flow."""
    from agents.orchestrator_agent import OrchestratorAgent

    orchestrator = OrchestratorAgent()

    result = await orchestrator.execute(AgentInput(
        session_id="e2e-orchestrator-001",
        data={"user_query": "æˆ‘åœ¨æ–°å®¿ç«™æƒ³å»ä½ çš„åå­—çš„åœ£åœ°"}
    ))

    assert result.success
    session = result.data["session"]
    assert session["bangumi_id"] == 160209
    assert len(session["points"]) > 0
```

#### 5.2 è¾¹ç•Œæµ‹è¯•

```python
@pytest.mark.asyncio
async def test_edge_case_empty_query():
    """Test empty query handling."""
    agent = BangumiResolverAgent()

    result = await agent.execute(AgentInput(
        session_id="edge-001",
        data={"user_query": ""}
    ))

    assert not result.success


@pytest.mark.asyncio
async def test_edge_case_no_bangumi_mentioned():
    """Test query with no bangumi."""
    agent = BangumiResolverAgent()

    result = await agent.execute(AgentInput(
        session_id="edge-002",
        data={"user_query": "ä»Šå¤©å¤©æ°”çœŸå¥½"}
    ))

    assert not result.success
    assert "bangumi" in result.error.lower()


@pytest.mark.asyncio
async def test_edge_case_multiple_name_variations():
    """Test that different name formats resolve to same ID."""
    agent = BangumiResolverAgent()

    variations = [
        "ä½ çš„åå­—",
        "ä½ çš„åå­—ã€‚",
        "å›ã®åã¯",
        "Your Name"
    ]

    results = []
    for var in variations:
        result = await agent.execute(AgentInput(
            session_id=f"var-{var}",
            data={"user_query": f"å»{var}çš„åœ£åœ°"}
        ))
        if result.success:
            results.append(result.data["id"])

    # All should resolve to same ID
    assert len(set(results)) == 1
    assert results[0] == 160209
```

#### 5.3 æ€§èƒ½æµ‹è¯•

```python
import time

@pytest.mark.slow
@pytest.mark.asyncio
async def test_performance_response_time():
    """Test that resolution completes within reasonable time."""
    agent = BangumiResolverAgent()

    start = time.time()
    result = await agent.execute(AgentInput(
        session_id="perf-001",
        data={"user_query": "æˆ‘æƒ³å»ä½ çš„åå­—çš„åœ£åœ°"}
    ))
    duration = time.time() - start

    assert result.success
    assert duration < 5.0, f"Too slow: {duration}s"
```

### è¿è¡Œæµ‹è¯•

```bash
# Run all tests
pytest tests/ -v

# Run only unit tests
pytest tests/unit/ -v

# Run only integration tests
pytest tests/integration/ -v --markers=integration

# Run with coverage
pytest tests/ --cov=. --cov-report=html
```

### éªŒæ”¶æ ‡å‡† (Stage 5)

- [x] å•å…ƒæµ‹è¯•è¦†ç›–ç‡ > 90%
- [x] é›†æˆæµ‹è¯•é€šè¿‡
- [x] è¾¹ç•Œæµ‹è¯•é€šè¿‡
- [x] æ€§èƒ½æµ‹è¯•é€šè¿‡
- [x] æ‰€æœ‰æµ‹è¯•ç»¿ç¯

---

## éªŒæ”¶æ ‡å‡†

### åŠŸèƒ½éªŒæ”¶

- [ ] BangumiClient æ­£å¸¸å·¥ä½œ
- [ ] BangumiResolverAgent æ­£å¸¸è§£æ
- [ ] SearchAgent æ”¯æŒä¸¤ç§æ¨¡å¼
- [ ] OrchestratorAgent é›†æˆæˆåŠŸ
- [ ] ç«¯åˆ°ç«¯æµç¨‹éªŒè¯

### è´¨é‡éªŒæ”¶

- [ ] æµ‹è¯•è¦†ç›–ç‡ > 90%
- [ ] æ‰€æœ‰æµ‹è¯•é€šè¿‡
- [ ] ä»£ç é€šè¿‡ `ruff` æ£€æŸ¥
- [ ] ä»£ç é€šè¿‡ `black` æ ¼å¼åŒ–
- [ ] æ–‡æ¡£å®Œæ•´ (docstring)
- [ ] æ—¥å¿—å®Œå–„

### æ€§èƒ½éªŒæ”¶

- [ ] å•æ¬¡è§£æ < 5ç§’
- [ ] LLM æå–å‡†ç¡®ç‡ > 95%
- [ ] LLM åŒ¹é…å‡†ç¡®ç‡ > 90%
- [ ] ç¼“å­˜å‘½ä¸­ç‡ > 80%

### ä»£ç è´¨é‡æ£€æŸ¥å‘½ä»¤

```bash
# Format code
black agents/ clients/ tests/

# Lint code
ruff check agents/ clients/ tests/

# Type check
mypy agents/ clients/

# Run tests with coverage
pytest tests/ --cov=. --cov-report=term-missing
```

---

## æ—¶é—´ä¼°ç®—

| é˜¶æ®µ | ä»»åŠ¡ | é¢„è®¡æ—¶é—´ |
|------|------|----------|
| Stage 1 | BangumiClient | 1.5 å°æ—¶ |
| Stage 2 | BangumiResolverAgent | 2.5 å°æ—¶ |
| Stage 3 | SearchAgent ä¿®æ”¹ | 1.5 å°æ—¶ |
| Stage 4 | OrchestratorAgent é›†æˆ | 1.0 å°æ—¶ |
| Stage 5 | å®Œæ•´æµ‹è¯•å¥—ä»¶ | 1.5 å°æ—¶ |
| **æ€»è®¡** | | **8 å°æ—¶** |

---

## å®æ–½æ£€æŸ¥æ¸…å•

### Stage 1 å®Œæˆæ ‡å‡†
- [ ] `clients/bangumi.py` åˆ›å»º
- [ ] `tests/unit/test_bangumi_client.py` é€šè¿‡
- [ ] æœç´¢åŠŸèƒ½éªŒè¯
- [ ] ç¼“å­˜æœºåˆ¶éªŒè¯
- [ ] ä»£ç æ ¼å¼åŒ–

### Stage 2 å®Œæˆæ ‡å‡†
- [ ] `agents/bangumi_resolver_agent.py` åˆ›å»º
- [ ] `tests/unit/test_bangumi_resolver_agent.py` é€šè¿‡
- [ ] LLM æå–éªŒè¯
- [ ] LLM åŒ¹é…éªŒè¯
- [ ] ç«¯åˆ°ç«¯æµ‹è¯•éªŒè¯

### Stage 3 å®Œæˆæ ‡å‡†
- [ ] `agents/search_agent.py` ä¿®æ”¹
- [ ] æ–°æ¨¡å¼æµ‹è¯•é€šè¿‡
- [ ] æ—§æ¨¡å¼å…¼å®¹æ€§éªŒè¯
- [ ] è·ç¦»è®¡ç®—éªŒè¯

### Stage 4 å®Œæˆæ ‡å‡†
- [ ] `agents/orchestrator_agent.py` ä¿®æ”¹
- [ ] é›†æˆæµ‹è¯•é€šè¿‡
- [ ] å·¥ä½œæµéªŒè¯

### Stage 5 å®Œæˆæ ‡å‡†
- [ ] é›†æˆæµ‹è¯•ç¼–å†™
- [ ] è¾¹ç•Œæµ‹è¯•ç¼–å†™
- [ ] æ€§èƒ½æµ‹è¯•é€šè¿‡
- [ ] è¦†ç›–ç‡è¾¾æ ‡

---

## ç›¸å…³æ–‡æ¡£

- [è®¾è®¡æ–‡æ¡£](./bangumi-resolver-agent-design.md)
- [Anitabi API æ–‡æ¡£](../anitabi-api-documentation.md)
- [Bangumi API å®˜æ–¹æ–‡æ¡£](https://bangumi.github.io/api/)
- [é¡¹ç›®å¼€å‘æŒ‡å—](../CLAUDE.md)

---

**ç»´æŠ¤è€…**: Seichijunrei Team
**æœ€åæ›´æ–°**: 2025-11-28
**ç‰ˆæœ¬**: 1.0
